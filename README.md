
# ğŸ“„ Video To Text Summarization

Welcome to the documentation for your GitHub repository! This guide provides installation instructions and example code snippets for each of the key technologies used in your project:

- **FFmpeg**
- **Whisper**
- **Ollama**
- **Streamlit**
- **Ngrok**

---

## ğŸ› ï¸ Technologies Used

- **FFmpeg** ğŸ¥: A multimedia framework for extracting audio from video files.  
- **Whisper** ğŸ™ï¸: An automatic speech recognition (ASR) system by OpenAI for transcribing audio.  
- **Ollama** ğŸ¤–: A language model for summarizing text.  
- **Streamlit** ğŸš€: A framework for building interactive web apps.  
- **Ngrok** ğŸŒ: A tool to expose local servers to the internet.  

---

## 1. FFmpeg ğŸ¥

### ğŸ“¥ Installation

**On Ubuntu:**

```bash
sudo apt update
sudo apt install ffmpeg
```

**On macOS (using Homebrew):**

```bash
brew install ffmpeg
```

**On Windows:**

Download the executable from the [official FFmpeg website](https://ffmpeg.org/download.html).

### ğŸš€ Example Code

```python
import ffmpeg

# Extract audio from a video file
ffmpeg.input('input_video.mp4').output('output_audio.mp3').run()
print("Audio extracted successfully! ğŸ‰")
```

---

## 2. Whisper ğŸ™ï¸

### ğŸ“¥ Installation

```bash
pip install openai-whisper
```

### ğŸš€ Example Code

```python
import whisper

# Load the Whisper model
model = whisper.load_model("base")

# Transcribe audio to text
result = model.transcribe("output_audio.mp3")

print("Transcription: ğŸ“")
print(result["text"])
```

---

## 3. Ollama ğŸ¤–

### ğŸ“¥ Installation

```bash
pip install langchain-ollama
```

### ğŸš€ Example Code

```python
from langchain_ollama import OllamaLLM

# Initialize Ollama
ollama_model = OllamaLLM(model="summarizer")

# Summarize text
summary = ollama_model.invoke("Summarize this text: Your long text goes here.")

print("Summary: ğŸ“„")
print(summary)
```

---

## 4. Streamlit ğŸš€

### ğŸ“¥ Installation

```bash
pip install streamlit
```

### ğŸš€ Example Code

```python
import streamlit as st

# Create a simple Streamlit app
st.title("Hello, Streamlit! ğŸ‘‹")
st.write("This is a simple web app built with Streamlit.")
```

### â–¶ï¸ Run the app

```bash
streamlit run app.py
```

---

## 5. Ngrok ğŸŒ

### ğŸ“¥ Installation

```bash
pip install pyngrok
```

### ğŸš€ Example Code

```python
from pyngrok import ngrok

# Start an Ngrok tunnel
public_url = ngrok.connect(addr="8000", proto="http")
print(f"Your app is now live at: {public_url} ğŸŒ")
```

---

## â†”ï¸ Flow

![Video To Text Summarization Flowchart](Video_To_Text_Summarization.png)

---

## â•°â”ˆâ¤ Next Steps

1. **Combine the Technologies**: Use FFmpeg, Whisper, Ollama, and Streamlit together to build a video-to-summary pipeline.  
2. **Deploy with Ngrok**: Share your app with others by exposing it using Ngrok.  
3. **Explore Further**: Customize the models, add new features, or integrate additional tools.  

---

## ğŸ§­ Explanation of Flowchart

1. ğŸŸ¢ **Start**: The process begins.  
2. ğŸ“¤ **Upload Video**: Upload your video file.  
3. ğŸµ **Extract Audio from Video**: Use **FFmpeg** to extract audio.  
4. ğŸ™ï¸ **Transcribe Audio**: Use **Whisper** to transcribe the audio into text.  
5. ğŸ“ **Display Transcribed Text**: Show transcribed text using **Streamlit**.  
6. ğŸ“„ **Summarize Text**: Use **Ollama** to summarize the transcribed text.  
7. ğŸ“‹ **Display Summary**: Display the summary using **Streamlit**.  
8. ğŸ **End**: The process concludes.
